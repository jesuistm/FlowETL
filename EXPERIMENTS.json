{
  "amazon_stock_data.csv": {
    "task": "Clean and prepare the Amazon stock dataset: standardise 'date' values to YYYY-MM-DD, filling missing dates using forward-fill. Convert all numeric columns ('open', 'high', 'low', 'close', 'adj_close', 'volume') to floats and impute missing values with the column median. Remove rows where all price fields are missing. Rename 'adj_close' to 'adjusted_close' for clarity, and trim extra spaces in text fields. Ensure consistency in numeric formats for downstream analysis."
  },
  "chemistry_field_data.csv": {
    "task": "Standardise the chemistry field dataset: trim spaces in identifiers like CHEMISTRY_ID, BIOMASS_ID, and ORGANISM_ID. Ensure 'ACTIVITY' is a valid percentage between 0–100; mark invalid values as null. Fill missing LATITUDE and LONGITUDE values with their respective column means. Convert 'ASSAY_DATE' to ISO format (YYYY-MM-DD). Finally, remove exact duplicate rows to ensure data integrity."
  },
  "chess_games.csv": {
    "task": "Clean and structure the chess games dataset: convert 'white_rating' and 'black_rating' to numeric values, imputing missing entries with the median. Trim spaces from player IDs and opening names. Standardise all timestamps in 'created_at' and 'last_move_at' to ISO 8601 format (YYYY-MM-DDTHH:MM:SSZ), leaving blanks as null. Remove duplicates using the 'id' field. Ensure 'turns' are integers (defaulting invalid values to 0). Rename 'rated' to 'is_rated' for clarity."
  },
  "financial_compliance.csv": {
    "task": "Prepare the financial compliance dataset for analysis: replace missing 'Firm_Name' and 'Industry_Affected' values with 'Unknown'. Convert all numeric columns (engagements, risk cases, compliance violations, fraud cases, revenue impact, workload, audit scores, satisfaction scores) to proper numeric types and impute missing values with the column medians. Clean the 'Year' field to ensure it uses four-digit years. Remove rows still missing critical fields like Total_Audit_Engagements or Total_Revenue_Impact after imputation. Rename 'AI_Used_for_Auditing' to 'AI_Audit_Flag' and standardise values as 'Yes' or 'No' (defaulting blanks to 'No'). Trim spaces from all text columns."
  },
  "netflix_users.csv": {
    "task": "Clean and standardise Netflix user data: ensure 'Age' falls between 0–120; replace invalid or missing values with 35. Fill missing 'Country' with 'USA'. Remove extra spaces in 'Name' and 'Favorite_Genre'. Make sure 'User_ID' is always a unique integer, assigning new IDs where necessary. Convert 'Last_Login' to the YYYY-MM-DD format consistently across the dataset."
  },
  "pixar_films.csv": {
    "task": "Standardise Pixar films data: convert 'run_time' into integer minutes and impute missing values with the median. Standardise 'release_date' to YYYY-MM-DD. Replace missing 'budget' with 100,000,000. Drop rows missing both 'film' and 'ID'. Fill missing 'film_rating' using the mode. Ensure numeric fields like box office and scores are properly typed. Trim spaces from text fields and remove duplicate entries based on the same film and release_date."
  },
  "smartwatch_readings.csv": {
    "task": "Prepare smartwatch readings: ensure 'User ID' is a valid integer and drop rows where it is missing or invalid. For 'Heart Rate (BPM)', impute missing values with the mean and enforce realistic limits (40–220). For 'Sleep Duration (hours)', replace missing values with the median and flag durations less than 2 or greater than 16 as outliers. Standardise 'Activity Level' by fixing inconsistent labels (e.g., unify Highly Active/Highly_Active, correct Seddentary to Sedentary). Trim extra spaces from text. Rename 'Blood Oxygen Level (%)' to 'blood_oxygen_percent' and 'Step Count' to 'step_count'."
  }
}
